{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import scipy.io\n",
    "import scipy.misc\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.pyplot import imshow\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pprint\n",
    "from cost_functions import *\n",
    "from misc_utils import *\n",
    "#from public_tests import *\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load VGG19 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_size = 128\n",
    "vgg = tf.keras.applications.VGG19(include_top=False,\n",
    "                                  input_shape=(img_size, img_size, 3),\n",
    "                                  weights='imagenet')\n",
    "\n",
    "vgg = replace_maxpool_with_avgpool(vgg)\n",
    "vgg.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chose your style and content layers. Uncomment the top to list all layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Chose layers to use when calculating style cost\n",
    "\n",
    "#for layer in vgg.layers:\n",
    "#    print(layer.name)\n",
    "\n",
    "STYLE_LAYERS = [\n",
    "    ('block1_conv1', 0.2),#200\n",
    "    #('block1_conv2', 0.2),\n",
    "    ('block2_conv1', 0.2),#20\n",
    "    #('block2_conv2', 0.2),\n",
    "    ('block3_conv1', 0.2),#20\n",
    "    #('block3_conv2', 0.2),\n",
    "    #('block3_conv3', 0.2),\n",
    "    ('block4_conv1', 0.2),#0.00002\n",
    "    #('block4_conv2', 0.2),\n",
    "    #('block4_conv3', 0.2),\n",
    "    #('block4_conv4', 0.2),\n",
    "    ('block5_conv1', 0.2),\n",
    "    #('block5_conv2', 0.2),\n",
    "    #('block5_conv3', 0.2),\n",
    "    #('block5_conv4', 0.2)\n",
    "    ]\n",
    "\n",
    "CONTENT_LAYERS = [('block4_conv1', 1)]\n",
    "\n",
    "INPUT_LAYERS = [(vgg.layers[0].name, 1)]\n",
    "\n",
    "vgg_style_outputs = get_layer_outputs(vgg, STYLE_LAYERS)\n",
    "vgg_model_content_outputs = get_layer_outputs(vgg, CONTENT_LAYERS)\n",
    "inputs_layer_output = get_layer_outputs(vgg, INPUT_LAYERS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_image, style_image, generated_image = load_images(\"images/sib.jpg\", \"images/monet.jpg\", img_size=img_size, white_noise=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the content image to be the input of the VGG model.  \n",
    "# Set a_C to be the hidden layer activation from the layer we have selected\n",
    "preprocessed_content =  tf.Variable(tf.image.convert_image_dtype(content_image, tf.float32))\n",
    "a_C = vgg_model_content_outputs(preprocessed_content)\n",
    "# Assign the input of the model to be the \"style\" image \n",
    "preprocessed_style =  tf.Variable(tf.image.convert_image_dtype(style_image, tf.float32))\n",
    "a_S = vgg_style_outputs(preprocessed_style)\n",
    "\n",
    "content_target = vgg_style_outputs(content_image)  # Content encoder\n",
    "style_targets = vgg_style_outputs(style_image)     # Style encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "\n",
    "#@tf.function()\n",
    "def train_step(generated_image):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # In this function you must use the precomputed encoded images a_S and a_C\n",
    "        \n",
    "        ### START CODE HERE\n",
    "        \n",
    "        # Compute a_G as the vgg_style_outputs for the current generated image\n",
    "        #(1 line)\n",
    "        a_G_s = vgg_style_outputs(generated_image)\n",
    "        a_G_c = vgg_model_content_outputs(generated_image)\n",
    "        \n",
    "        # Getting the original image for denoising\n",
    "        a_I = inputs_layer_output(generated_image)\n",
    "        \n",
    "        # Compute the style cost\n",
    "        #(1 line)\n",
    "        J_style = compute_style_cost(a_S, a_G_s, STYLE_LAYERS)\n",
    "        \n",
    "        #(2 lines)\n",
    "        # Compute the content cost\n",
    "        J_content = compute_content_cost(a_C,a_G_c)\n",
    "        \n",
    "        \n",
    "        #J_noise = compute_noise_cost(a_I)\n",
    "        J_noise = 0\n",
    "        \n",
    "        # Compute the total cost\n",
    "        J = total_cost(J_content, J_style, J_noise, alpha = 4, beta = 4000, gamma = 0)\n",
    "        \n",
    "        ### END CODE HERE\n",
    "        \n",
    "    grad = tape.gradient(J, generated_image)\n",
    "\n",
    "    optimizer.apply_gradients([(grad, generated_image)])\n",
    "    generated_image.assign(clip_0_1(generated_image))\n",
    "    \n",
    "    # For grading purposes\n",
    "    return J, J_style, J_content, J_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the generated image at some epochs\n",
    "# Uncomment to reset the style transfer process. You will need to compile the train_step function again \n",
    "epochs = 1\n",
    "for i in range(epochs):\n",
    "    J, J_style, J_content, J_noise = train_step(generated_image)\n",
    "    if i % 25 == 0:\n",
    "        print(f\"Epoch {i} with J: {J}, J_style: {J_style}, J_content: {J_content}, J_noise: {J_noise}\")\n",
    "        \n",
    "    if i % 500 == 0:\n",
    "        image = tensor_to_image(generated_image)\n",
    "        imshow(image)\n",
    "        image.save(f\"output/image_test_{i}.jpg\")\n",
    "        plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_G_s = vgg_style_outputs(generated_image)\n",
    "J_style = compute_style_cost(a_S, a_G_s, STYLE_LAYERS, layer_wise_output=True)\n",
    "for i, layer_cost in enumerate(J_style):\n",
    "   print(f\"Layer {STYLE_LAYERS[i]} cost: {layer_cost}\")\n",
    "\n",
    "print(tf.nn.softmax(J_style))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the 3 images in a row\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "imshow(content_image[0])\n",
    "ax.title.set_text('Content image')\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "imshow(style_image[0])\n",
    "ax.title.set_text('Style image')\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "imshow(generated_image[0])\n",
    "ax.title.set_text('Generated image')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
